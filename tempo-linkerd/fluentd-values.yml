---

# Fluentd image
image:
  repository: "ricsanfre/fluentd-aggregator"
  pullPolicy: "IfNotPresent"
  tag: "v1.15.2-debian-1.0"

# Deploy fluentd as deployment
kind: "Deployment"
# Number of replicas
replicaCount: 1
# Enabling HPA
autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80

# Do not create serviceAccount and RBAC. Fluentd does not need to get access to kubernetes API.
serviceAccount:
  create: false
rbac:
  create: false

## Additional environment variables to set for fluentd pods
env:
  - name: LOKI_URL
    value: "http://loki-gateway.loki.svc.cluster.local"
  - name: LOKI_USERNAME
    value: ""
  - name: LOKI_PASSWORD
    value: ""
 

# Service. Exporting forwarder port (Metric already exposed by chart)
service:
  type: "ClusterIP"
  annotations: {}
  ports:
  - name: forwarder
    protocol: TCP
    containerPort: 24224

## Fluentd list of plugins to install
##
plugins: []
# - fluent-plugin-out-http

## Do not create additional config maps
##
configMapConfigs: []

## Fluentd configurations:
##
fileConfigs:
  01_sources.conf: |-
    ## logs from fluentbit forwarders
    <source>
      @type forward
      @label @FORWARD
      bind "#{ENV['FLUENTD_FORWARD_BIND'] || '0.0.0.0'}"
      port "#{ENV['FLUENTD_FORWARD_PORT'] || '24224'}"
    </source>
    ## Enable Prometheus end point
    <source>
      @type prometheus
      @id in_prometheus
      bind "0.0.0.0"
      port 24231
      metrics_path "/metrics"
    </source>
    <source>
      @type prometheus_monitor
      @id in_prometheus_monitor
    </source>
    <source>
      @type prometheus_output_monitor
      @id in_prometheus_output_monitor
    </source>
  02_filters.conf: |-
    <label @FORWARD>
      # Re-route fluentd logs. Discard them
      <match kube.var.log.containers.fluentd**>
        @type relabel
        @label @FLUENT_LOG
      </match>
      ## Get kubernetes fields
      <filter kube.**>
        @type record_modifier
        remove_keys kubernetes, __dummy__, __dummy2__
        <record>
          __dummy__   ${ p = record["kubernetes"]["labels"]["app"]; p.nil? ? p : record['app'] = p; }
          __dummy2__   ${ p = record["kubernetes"]["labels"]["app.kubernetes.io/name"]; p.nil? ? p : record['app'] = p; }
          namespace ${ record.dig("kubernetes","namespace_name") }
          pod ${ record.dig("kubernetes", "pod_name") }
          container ${ record.dig("kubernetes", "container_name") }
          node_name ${ record.dig("kubernetes", "host")}
        </record>
      </filter>
      ## Avoid ES rejection due to conflicting field types when using fluentbit merge_log
      <filter kube.**>
        @type record_transformer
        enable_ruby true
        remove_keys log_processed
        <record>
          json_message.${record["container"]} ${(record.has_key?('log_processed'))? record['log_processed'] : nil}
        </record>
      </filter>
      <match **>
        @type relabel
        @label @DISPATCH
      </match>
    </label>
  03_dispatch.conf: |-
    <label @DISPATCH>
      # Calculate prometheus metrics
      <filter **>
        @type prometheus
        <metric>
          name fluentd_input_status_num_records_total
          type counter
          desc The total number of incoming records
          <labels>
            tag ${tag}
            hostname ${hostname}
          </labels>
        </metric>
      </filter>
      # Copy log stream to different outputs
      <match **>
        @type copy
        <store>
          @type relabel
          @label @OUTPUT_LOKI
        </store>
        <store>
          @type relabel
          @label @OUTPUT_STDOUT
        </store>  
      </match>
    </label>
  04_outputs.conf: |-
    <label @OUTPUT_LOKI>
      # Send received logs to Loki
      <match kube.**>
        @type loki
        @id out_loki
        @log_level info
        url "#{ENV['LOKI_URL']}"
        username "#{ENV['LOKI_USERNAME'] || use_default}"
        password "#{ENV['LOKI_PASSWORDD'] || use_default}"
        extra_labels {"job": "fluentd"}
        <label>
           app
           container
           pod
           namespace
           node_name
        </label>
      </match>
    </label>
    <label @OUTPUT_STDOUT>
      # Send received logs to elasticsearch
      <match **>
        @type stdout
      </match>
    </label>

